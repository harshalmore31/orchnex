# src/demo.py
from rich.console import Console
from rich.prompt import Prompt
from orchnex import LLMConfig, MultiLLMOrchestrator
import os

def run_interactive_demo():
    console = Console()
    
    # ASCII Art Header
    console.print("""
    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
    â•‘            ğŸŒŸ ORCHNEX DEMO ğŸŒŸ             â•‘
    â•‘    Multi-LLM Orchestration Platform       â•‘
    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """, style="bold blue")
    
    # Initialize configuration
    config = LLMConfig(
        gemini_api_key=os.getenv("GEMINI_API_KEY") or input("Enter GEMINI_API_KEY : "),
        nvidia_api_key=os.getenv("NVIDIA_API_KEY") or input("Enter NVIDIA_API_KEY : ")
    )
    
    orchestrator = MultiLLMOrchestrator(config)
    
    # Show capabilities
    console.print("\nğŸ”¥ Available Capabilities:", style="bold yellow")
    capabilities = [
        "âœ¨ Prompt Enhancement via PromptMaster 3.0",
        "ğŸ¤– Multi-LLM Processing Pipeline",
        "ğŸ“Š Quality Analysis and Refinement",
        "ğŸ”„ Iterative Improvement Loop",
        "ğŸ“ˆ Performance Metrics"
    ]
    for cap in capabilities:
        console.print(f"  {cap}")
    
    # Interactive demo
    while True:
        try:
            prompt = Prompt.ask("\n\nğŸ’­ Enter your prompt (or 'quit' to exit)")
            
            if prompt.lower() == 'quit':
                break
                
            console.print("\nğŸ¯ Processing your request through the orchestration pipeline...\n")
            result = orchestrator.process_input(prompt, verbose=True)
            
        except KeyboardInterrupt:
            console.print("\n\nâŒ Demo interrupted by user")
            break
        except Exception as e:
            console.print(f"\nâŒ Error: {str(e)}", style="bold red")

if __name__ == "__main__":
    run_interactive_demo()